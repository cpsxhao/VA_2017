{
 "cells": [
  {
   "cell_type": "code",
   "execution_count": 1,
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "[]\n"
     ]
    }
   ],
   "source": [
    "import sys\n",
    "from IPython import embed\n",
    "sys.argv[0:] = []\n",
    "print(sys.argv)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "# %load train.py\n",
    "#!/usr/bin/env python\n",
    "\n",
    "\n",
    "\n",
    "from __future__ import print_function\n",
    "import argparse\n",
    "import random\n",
    "import time\n",
    "import os\n",
    "import numpy as np\n",
    "from optparse import OptionParser\n",
    "\n",
    "import torch\n",
    "import torch.backends.cudnn as cudnn\n",
    "import torch.optim as optim\n",
    "from torch.autograd import Variable\n",
    "from torch.optim.lr_scheduler import LambdaLR as LR_Policy\n",
    "\n",
    "import models\n",
    "from dataset import VideoFeatDataset as dset\n",
    "from tools.config_tools import Config\n",
    "from tools import utils\n",
    "\n",
    "\n",
    "parser = OptionParser()\n",
    "parser.add_option('--config',\n",
    "                  type=str,\n",
    "                  help=\"training configuration\",\n",
    "                  default=\"./configs/train_config.yaml\")\n",
    "\n",
    "(opts, args) = parser.parse_args()\n",
    "assert isinstance(opts, object)\n",
    "opt = Config(opts.config)\n",
    "print(opt)\n",
    "\n",
    "if opt.checkpoint_folder is None:\n",
    "    opt.checkpoint_folder = 'checkpoints'\n",
    "\n",
    "# make dir\n",
    "if not os.path.exists(opt.checkpoint_folder):\n",
    "    os.system('mkdir {0}'.format(opt.checkpoint_folder))\n",
    "\n",
    "train_dataset = dset(opt.data_dir, flist=opt.flist)\n",
    "\n",
    "print('number of train samples is: {0}'.format(len(train_dataset)))\n",
    "print('finished loading data')\n",
    "\n",
    "\n",
    "if opt.manualSeed is None:\n",
    "    opt.manualSeed = random.randint(1, 10000)\n",
    "\n",
    "if torch.cuda.is_available() and not opt.cuda:\n",
    "    print(\"WARNING: You have a CUDA device, so you should probably run with \\\"cuda: True\\\"\")\n",
    "    torch.manual_seed(opt.manualSeed)\n",
    "else:\n",
    "    if int(opt.ngpu) == 1:\n",
    "        print('so we use 1 gpu to training')\n",
    "        print('setting gpu on gpuid {0}'.format(opt.gpu_id))\n",
    "\n",
    "        if opt.cuda:\n",
    "            os.environ['CUDA_VISIBLE_DEVICES'] = opt.gpu_id\n",
    "            torch.cuda.manual_seed(opt.manualSeed)\n",
    "            cudnn.benchmark = True\n",
    "print('Random Seed: {0}'.format(opt.manualSeed))\n",
    "\n",
    "\n",
    "# training function for metric learning\n",
    "def train(train_loader, model, criterion, optimizer, epoch, opt):\n",
    "    \"\"\"\n",
    "    train for one epoch on the training set\n",
    "    \"\"\"\n",
    "    batch_time = utils.AverageMeter()\n",
    "    losses = utils.AverageMeter()\n",
    "\n",
    "    # training mode\n",
    "    model.train()\n",
    "\n",
    "    end = time.time()\n",
    "    for i, (vfeat, afeat) in enumerate(train_loader):\n",
    "        # shuffling the index orders\n",
    "        bz = vfeat.size()[0]\n",
    "        orders = np.arange(bz).astype('int32')\n",
    "        shuffle_orders = orders.copy()\n",
    "        np.random.shuffle(shuffle_orders)\n",
    "\n",
    "        # creating a new data with the shuffled indices\n",
    "        afeat2 = afeat[torch.from_numpy(shuffle_orders).long()].clone()\n",
    "\n",
    "        # concat the vfeat and afeat respectively\n",
    "        afeat0 = torch.cat((afeat, afeat2), 0)\n",
    "        vfeat0 = torch.cat((vfeat, vfeat), 0)\n",
    "\n",
    "        # generating the labels\n",
    "        # 1. the labels for the shuffled feats\n",
    "        label1 = (orders == shuffle_orders + 0).astype('float32')\n",
    "        target1 = torch.from_numpy(label1)\n",
    "\n",
    "        # 2. the labels for the original feats\n",
    "        label2 = label1.copy()\n",
    "        label2[:] = 1\n",
    "        target2 = torch.from_numpy(label2)\n",
    "\n",
    "        # concat the labels together\n",
    "        target = torch.cat((target2, target1), 0)\n",
    "        target = 1 - target\n",
    "\n",
    "        # transpose the feats\n",
    "        vfeat0 = vfeat0.transpose(2, 1)\n",
    "        afeat0 = afeat0.transpose(2, 1)\n",
    "\n",
    "        # put the data into Variable\n",
    "        vfeat_var = Variable(vfeat0)\n",
    "        afeat_var = Variable(afeat0)\n",
    "        target_var = Variable(target)\n",
    "\n",
    "        # if you have gpu, then shift data to GPU\n",
    "        if opt.cuda:\n",
    "            vfeat_var = vfeat_var.cuda()\n",
    "            afeat_var = afeat_var.cuda()\n",
    "            target_var = target_var.cuda()\n",
    "\n",
    "        # forward, backward optimize\n",
    "        sim = model(vfeat_var, afeat_var)   # inference simialrity\n",
    "        loss = criterion(sim, target_var)   # compute contrastive loss\n",
    "\n",
    "        ##############################\n",
    "        # update loss in the loss meter\n",
    "        ##############################\n",
    "        losses.update(loss.data[0], vfeat0.size(0))\n",
    "\n",
    "        ##############################\n",
    "        # compute gradient and do sgd\n",
    "        ##############################\n",
    "        optimizer.zero_grad()\n",
    "        loss.backward()\n",
    "\n",
    "        ##############################\n",
    "        # gradient clip stuff\n",
    "        ##############################\n",
    "        #utils.clip_gradient(optimizer, opt.gradient_clip)\n",
    "\n",
    "        # update parameters\n",
    "        optimizer.step()\n",
    "\n",
    "        # measure elapsed time\n",
    "        batch_time.update(time.time() - end)\n",
    "        end = time.time()\n",
    "        if i % opt.print_freq == 0:\n",
    "            log_str = 'Epoch: [{0}][{1}/{2}]\\t Time {batch_time.val:.3f} ({batch_time.avg:.3f})\\t Loss {loss.val:.4f} ({loss.avg:.4f})'.format(epoch, i, len(train_loader), batch_time=batch_time, loss=losses)\n",
    "            print(log_str)\n",
    "\n",
    "\n",
    "def main():\n",
    "    global opt\n",
    "    # train data loader\n",
    "    train_loader = torch.utils.data.DataLoader(train_dataset, batch_size=opt.batchSize,\n",
    "                                     shuffle=True, num_workers=int(opt.workers))\n",
    "\n",
    "    # create model\n",
    "    model = models.VAMetric2()\n",
    "\n",
    "    if opt.init_model != '':\n",
    "        print('loading pretrained model from {0}'.format(opt.init_model))\n",
    "        model.load_state_dict(torch.load(opt.init_model))\n",
    "\n",
    "    # Contrastive Loss\n",
    "    criterion = models.ContrastiveLoss()\n",
    "\n",
    "    if opt.cuda:\n",
    "        print('shift model and criterion to GPU .. ')\n",
    "        model = model.cuda()\n",
    "        criterion = criterion.cuda()\n",
    "\n",
    "    # optimizer\n",
    "    optimizer = optim.SGD(model.parameters(), opt.lr,\n",
    "                                momentum=opt.momentum,\n",
    "                                weight_decay=opt.weight_decay)\n",
    "\n",
    "    # adjust learning rate every lr_decay_epoch\n",
    "    lambda_lr = lambda epoch: opt.lr_decay ** ((epoch + 1) // opt.lr_decay_epoch)   #poly policy\n",
    "    scheduler = LR_Policy(optimizer, lambda_lr)\n",
    "\n",
    "    for epoch in range(resume_epoch, opt.max_epochs):\n",
    "        embed()\n",
    "    \t#################################\n",
    "        # train for one epoch\n",
    "        #################################\n",
    "        train(train_loader, model, criterion, optimizer, epoch, opt)\n",
    "        scheduler.step()\n",
    "\n",
    "        ##################################\n",
    "        # save checkpoints\n",
    "        ##################################\n",
    "\n",
    "        # save model every 10 epochs\n",
    "        if ((epoch+1) % opt.epoch_save) == 0:\n",
    "            path_checkpoint = '{0}/{1}_state_epoch{2}.pth'.format(opt.checkpoint_folder, opt.prefix, epoch+1)\n",
    "            utils.save_checkpoint(model.state_dict(), path_checkpoint)\n",
    "\n",
    "if __name__ == '__main__':\n",
    "    main()\n"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {
    "scrolled": true
   },
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "self.cuda=True\n",
      "self.ngpu=1\n",
      "self.gpu_id='4'\n",
      "self.data_dir='/home/lih/RemoteRepo/VA_Project/Train'\n",
      "self.video_flist='/home/lih/RemoteRepo/VA_Project/proj_demo/filelists/Video_Name_List.txt'\n",
      "self.audio_flist='/home/lih/RemoteRepo/VA_Project/proj_demo/filelists/Audio_Name_List.txt'\n",
      "self.workers=4\n",
      "self.batchSize=40\n",
      "self.checkpoint_folder='/home/lih/RemoteRepo/VA_Project/proj_demo/checkpoints'\n",
      "self.init_model='/home/lih/RemoteRepo/VA_Project/proj_demo/checkpoints/VA_METRIC_state_epoch160.pth'\n",
      "self.topk=5\n",
      "<tools.config_tools.Config object at 0x7f91f6a97d30>\n",
      "number of test samples is: 30\n",
      "finished loading data\n",
      "so we use gpu 1 for testing\n",
      "setting gpu on gpuid 4\n",
      "loading pretrained model from /home/lih/RemoteRepo/VA_Project/proj_demo/checkpoints/VA_METRIC_state_epoch160.pth\n",
      "shift model to GPU .. \n",
      "Python 3.6.2 |Continuum Analytics, Inc.| (default, Jul 20 2017, 13:51:32) \n",
      "Type 'copyright', 'credits' or 'license' for more information\n",
      "IPython 6.1.0 -- An enhanced Interactive Python. Type '?' for help.\n",
      "\n",
      "In [1]: model\n",
      "Out[1]: \n",
      "VAMetric2 (\n",
      "  (mp): MaxPool1d (size=120, stride=120, padding=0, dilation=1, ceil_mode=False)\n",
      "  (vfc): Linear (1024 -> 128)\n",
      "  (fc): Linear (128 -> 96)\n",
      ")\n",
      "\n",
      "In [2]: enumerate(video_loader)\n",
      "Out[2]: <enumerate at 0x7f91ed50e828>\n",
      "\n",
      "In [3]: video_loader\n",
      "Out[3]: <torch.utils.data.dataloader.DataLoader at 0x7f91f6a13e80>\n",
      "\n",
      "In [4]: len(video_loader)\n",
      "Out[4]: 1\n",
      "\n",
      "In [5]: next\n",
      "Out[5]: <function next>\n",
      "\n",
      "In [6]: next()\n",
      "\u001b[0;31m---------------------------------------------------------------------------\u001b[0m\n",
      "\u001b[0;31mTypeError\u001b[0m                                 Traceback (most recent call last)\n",
      "\u001b[0;32m<ipython-input-6-b80b41363c01>\u001b[0m in \u001b[0;36m<module>\u001b[0;34m()\u001b[0m\n",
      "\u001b[0;32m----> 1\u001b[0;31m \u001b[0mnext\u001b[0m\u001b[0;34m(\u001b[0m\u001b[0;34m)\u001b[0m\u001b[0;34m\u001b[0m\u001b[0m\n",
      "\u001b[0m\n",
      "\u001b[0;31mTypeError\u001b[0m: next expected at least 1 arguments, got 0\n",
      "\n"
     ]
    }
   ],
   "source": [
    "# %load evaluate.py\n",
    "#!/usr/bin/env python\n",
    "\n",
    "from __future__ import print_function\n",
    "from __future__ import division\n",
    "\n",
    "import os\n",
    "import numpy as np\n",
    "from optparse import OptionParser\n",
    "\n",
    "import torch\n",
    "import torch.backends.cudnn as cudnn\n",
    "from torch.autograd import Variable\n",
    "\n",
    "import models\n",
    "from dataset import VideoFeatDataset as dset\n",
    "from tools.config_tools import Config\n",
    "from tools import utils\n",
    "\n",
    "\n",
    "parser = OptionParser()\n",
    "parser.add_option('--config',\n",
    "                  type=str,\n",
    "                  help=\"evaluation configuration\",\n",
    "                  default=\"/home/lih/RemoteRepo/VA_Project/proj_demo/configs/test_config.yaml\")\n",
    "\n",
    "(opts, args) = parser.parse_args()\n",
    "assert isinstance(opts, object)\n",
    "opt = Config(opts.config)\n",
    "print(opt)\n",
    "\n",
    "if opt.checkpoint_folder is None:\n",
    "    opt.checkpoint_folder = 'checkpoints'\n",
    "\n",
    "test_video_dataset = dset(opt.data_dir, opt.video_flist, which_feat='vfeat')\n",
    "test_audio_dataset = dset(opt.data_dir, opt.audio_flist, which_feat='afeat')\n",
    "\n",
    "print('number of test samples is: {0}'.format(len(test_video_dataset)))\n",
    "print('finished loading data')\n",
    "\n",
    "\n",
    "if torch.cuda.is_available() and not opt.cuda:\n",
    "    print(\"WARNING: You have a CUDA device, so you should probably run with \\\"cuda: True\\\"\")\n",
    "else:\n",
    "    if int(opt.ngpu) == 1:\n",
    "        print('so we use gpu 1 for testing')\n",
    "        os.environ['CUDA_VISIBLE_DEVICES'] = opt.gpu_id\n",
    "        cudnn.benchmark = True\n",
    "        print('setting gpu on gpuid {0}'.format(opt.gpu_id))\n",
    "\n",
    "# test function for metric learning\n",
    "def test(video_loader, audio_loader, model, opt):\n",
    "    \"\"\"\n",
    "    train for one epoch on the training set\n",
    "    \"\"\"\n",
    "    embed();\n",
    "    \n",
    "    # training mode\n",
    "    model.eval()\n",
    "\n",
    "    sim_mat = []\n",
    "    right = 0\n",
    "    for _, vfeat in enumerate(video_loader):\n",
    "        for _, afeat in enumerate(audio_loader):\n",
    "            \n",
    "            embed();\n",
    "            \n",
    "            # transpose feats\n",
    "            vfeat = vfeat.transpose(2,1)\n",
    "            afeat = afeat.transpose(2,1)\n",
    "\n",
    "            # shuffling the index orders\n",
    "            bz = vfeat.size()[0]\n",
    "            for k in np.arange(bz):\n",
    "                cur_vfeat = vfeat[k].clone()\n",
    "                cur_vfeats = cur_vfeat.repeat(bz, 1, 1)\n",
    "\n",
    "                vfeat_var = Variable(cur_vfeats)\n",
    "                afeat_var = Variable(afeat)\n",
    "\n",
    "                if opt.cuda:\n",
    "                    vfeat_var = vfeat_var.cuda()\n",
    "                    afeat_var = afeat_var.cuda()\n",
    "\n",
    "                cur_sim = model(vfeat_var, afeat_var)\n",
    "                if k == 0:\n",
    "                    simmat = cur_sim.clone()\n",
    "                else:\n",
    "                    simmat = torch.cat((simmat, cur_sim), 1)\n",
    "            embed();\n",
    "            \n",
    "            sorted, indices = torch.sort(simmat, 0)\n",
    "            np_indices = indices.cpu().data.numpy()\n",
    "            topk = np_indices[:opt.topk,:]\n",
    "            for k in np.arange(bz):\n",
    "                order = topk[:,k]\n",
    "                if k in order:\n",
    "                    right = right + 1\n",
    "            print('The similarity matrix: \\n {}'.format(simmat))\n",
    "            print('Testing accuracy (top{}): {:.3f}'.format(opt.topk, right/bz))\n",
    "\n",
    "def main():\n",
    "    global opt\n",
    "    # test data loader\n",
    "    test_video_loader = torch.utils.data.DataLoader(test_video_dataset, batch_size=opt.batchSize,\n",
    "                                     shuffle=False, num_workers=int(opt.workers))\n",
    "    test_audio_loader = torch.utils.data.DataLoader(test_audio_dataset, batch_size=opt.batchSize,\n",
    "                                     shuffle=False, num_workers=int(opt.workers))\n",
    "\n",
    "    # create model\n",
    "    model = models.VAMetric2()\n",
    "\n",
    "    if opt.init_model != '':\n",
    "        print('loading pretrained model from {0}'.format(opt.init_model))\n",
    "        model.load_state_dict(torch.load(opt.init_model))\n",
    "\n",
    "    if opt.cuda:\n",
    "        print('shift model to GPU .. ')\n",
    "        model = model.cuda()\n",
    "\n",
    "    test(test_video_loader, test_audio_loader, model, opt)\n",
    "\n",
    "\n",
    "if __name__ == '__main__':\n",
    "    main()\n"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "model"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {
    "collapsed": true
   },
   "outputs": [],
   "source": []
  }
 ],
 "metadata": {
  "kernelspec": {
   "display_name": "Python [conda env:pytorch]",
   "language": "python",
   "name": "conda-env-pytorch-py"
  },
  "language_info": {
   "codemirror_mode": {
    "name": "ipython",
    "version": 3
   },
   "file_extension": ".py",
   "mimetype": "text/x-python",
   "name": "python",
   "nbconvert_exporter": "python",
   "pygments_lexer": "ipython3",
   "version": "3.6.2"
  },
  "toc": {
   "nav_menu": {},
   "number_sections": true,
   "sideBar": true,
   "skip_h1_title": false,
   "toc_cell": false,
   "toc_position": {},
   "toc_section_display": "block",
   "toc_window_display": false
  },
  "varInspector": {
   "cols": {
    "lenName": 16,
    "lenType": 16,
    "lenVar": 40
   },
   "kernels_config": {
    "python": {
     "delete_cmd_postfix": "",
     "delete_cmd_prefix": "del ",
     "library": "var_list.py",
     "varRefreshCmd": "print(var_dic_list())"
    },
    "r": {
     "delete_cmd_postfix": ") ",
     "delete_cmd_prefix": "rm(",
     "library": "var_list.r",
     "varRefreshCmd": "cat(var_dic_list()) "
    }
   },
   "types_to_exclude": [
    "module",
    "function",
    "builtin_function_or_method",
    "instance",
    "_Feature"
   ],
   "window_display": false
  }
 },
 "nbformat": 4,
 "nbformat_minor": 2
}
